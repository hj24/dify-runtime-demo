id: intelligent_qa_demo
version: "1.0"
start: extract_keywords

inputs:
  question: string

nodes:
  # æ­¥éª¤1: æå–é—®é¢˜ä¸­çš„å…³é”®è¯
  extract_keywords:
    type: llm
    inputs:
      model: "gpt-3.5-turbo"
      prompt: |
        Extract 3-5 key concepts from this question: {{ inputs.question }}
        Return ONLY the keywords as a comma-separated list.
      temperature: 0.3
    next: [generate_outline, search_context]

  # æ­¥éª¤2: åŸºäºé—®é¢˜ç”Ÿæˆç­”æ¡ˆå¤§çº²ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
  generate_outline:
    type: llm
    inputs:
      model: "gpt-3.5-turbo"
      prompt: |
        Create a brief outline for answering this question: {{ inputs.question }}
        Use bullet points.
      temperature: 0.7

  # æ­¥éª¤3: æ¨¡æ‹Ÿæœç´¢ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
  search_context:
    type: mock_search
    inputs:
      keywords: "{{ extract_keywords.text }}"

  # æ­¥éª¤4: ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
  generate_final_answer:
    type: llm
    depends_on:
      - extract_keywords
      - generate_outline
      - search_context
    inputs:
      model: "gpt-4o-mini"
      prompt: |
        Question: {{ inputs.question }}
        
        Keywords extracted: {{ extract_keywords.text }}
        
        Answer outline:
        {{ generate_outline.text }}
        
        Context information:
        {{ search_context.results }}
        
        Now provide a comprehensive answer to the question, incorporating the above information.
      temperature: 0.5
    next: [format_response]

  # æ­¥éª¤5: æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º
  format_response:
    type: format
    depends_on:
      - generate_final_answer
    inputs:
      template: |
        ğŸ” Keywords: {{ extract_keywords.text }}
        
        ğŸ“ Answer:
        {{ generate_final_answer.text }}
        
        â„¹ï¸ Sources: {{ search_context.sources }}
    end: true
